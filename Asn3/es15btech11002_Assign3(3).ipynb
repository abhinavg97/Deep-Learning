{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "class LSTM:\n",
    "    def sigmoid(self, x):\n",
    "        return (1/(1+np.exp(-x)))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return (x*(1-x))\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return (1-(np.tanh(x))**2)\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "\n",
    "        self.U_i = np.random.uniform(-0.1, 0.1, size=(input_dim, output_dim))\n",
    "        self.U_f = np.random.uniform(-0.1, 0.1, size=(input_dim, output_dim))\n",
    "        self.U_o = np.random.uniform(-0.1, 0.1, size=(input_dim, output_dim))\n",
    "        self.U_g = np.random.uniform(-0.1, 0.1, size=(input_dim, output_dim))\n",
    "        self.W_i = np.random.uniform(-0.1, 0.1, size=(output_dim, output_dim))\n",
    "        self.W_f = np.random.uniform(-0.1, 0.1, size=(output_dim, output_dim))\n",
    "        self.W_o = np.random.uniform(-0.1, 0.1, size=(output_dim, output_dim))\n",
    "        self.W_g = np.random.uniform(-0.1, 0.1, size=(output_dim, output_dim))\n",
    "\n",
    "        self.cell_state = np.zeros((1, output_dim))\n",
    "        self.output_state = np.zeros((1, output_dim))\n",
    "\n",
    "        # caching for backpropagation\n",
    "        self.input_gates = list()\n",
    "        self.forget_gates = list()\n",
    "        self.output_gates = list()\n",
    "        self.gs = list()\n",
    "        self.cell_states = list()\n",
    "        self.output_states = list()\n",
    "\n",
    "        # caching for backpropagation\n",
    "        self.del_output_states = list()\n",
    "        self.del_cell_states = list()\n",
    "        self.del_gs = list()\n",
    "        self.del_input_gates = list()\n",
    "        self.del_forget_gates = list()\n",
    "        self.del_output_gates = list()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_gate = self.sigmoid(np.dot(x, self.U_i) + np.dot(self.output_state, self.W_i))\n",
    "        forget_gate = self.sigmoid(np.dot(x, self.U_f) + np.dot(self.output_state, self.W_f))\n",
    "        output_gate = self.sigmoid(np.dot(x, self.U_o) + np.dot(self.output_state, self.W_o))\n",
    "        g = np.tanh(np.dot(x, self.U_g) + np.dot(self.output_state, self.W_g))\n",
    "        self.cell_state = self.cell_state*forget_gate + g*input_gate\n",
    "        self.output_state = np.tanh(self.cell_state)*output_gate\n",
    "\n",
    "        self.input_gates.append(input_gate)\n",
    "        self.forget_gates.append(forget_gate)\n",
    "        self.output_gates.append(output_gate)\n",
    "        self.gs.append(g)\n",
    "        self.cell_states.append(self.cell_state)\n",
    "        self.output_states.append(self.output_state)\n",
    "\n",
    "    def backward(self, x, y, seq_length, lr):\n",
    "        timestep_error = 0\n",
    "        future_del_cell_state = 0\n",
    "\n",
    "        for a in range(seq_length):\n",
    "            if a == 0:\n",
    "                future_forget_gate = np.zeros_like(self.forget_gates[0])\n",
    "            else:\n",
    "                future_forget_gate = self.forget_gates[seq_length-a]\n",
    "            if a == seq_length:\n",
    "                prev_cell_state = np.zeros_like(self.cell_states[0])\n",
    "            else:\n",
    "                prev_cell_state = self.cell_states[seq_length-a-2]\n",
    "            error = self.output_states[seq_length-a-1] - y[seq_length-a-1]\n",
    "            del_output_state = error + timestep_error\n",
    "            del_cell_state = del_output_state*self.output_gates[seq_length-a-1]*self.tanh_derivative(self.cell_states[seq_length-a-1]) + future_del_cell_state*future_forget_gate\n",
    "            del_g = del_cell_state*self.input_gates[seq_length-a-1]*self.tanh_derivative(self.gs[seq_length-a-1])\n",
    "            del_input_gate = del_cell_state*self.gs[seq_length-a-1]*self.sigmoid_derivative(self.input_gates[seq_length-a-1])\n",
    "            del_forget_gate = del_cell_state*prev_cell_state*self.sigmoid_derivative(self.forget_gates[seq_length-a-1])\n",
    "            del_output_gate = del_output_state*np.tanh(self.cell_states[seq_length-a-1])*self.sigmoid_derivative(self.output_gates[seq_length-a-1])\n",
    "\n",
    "            timestep_error = (np.dot(self.W_i, del_input_gate.T) + np.dot(self.W_f, del_forget_gate.T) + np.dot(self.W_o, del_output_gate.T) + np.dot(self.W_g, del_g.T)).T\n",
    "            future_del_cell_state = del_cell_state\n",
    "\n",
    "            self.del_output_states.append(del_output_state)\n",
    "            self.del_cell_states.append(del_cell_state)\n",
    "            self.del_gs.append(del_g)\n",
    "            self.del_input_gates.append(del_input_gate)\n",
    "            self.del_forget_gates.append(del_forget_gate)\n",
    "            self.del_output_gates.append(del_output_gate)\n",
    "\n",
    "        #UPDATE WEIGHTS\n",
    "        self.U_i -= np.dot(x.T, np.flip(np.array(self.del_input_gates).reshape((len(self.del_input_gates), -1)), axis=0))*lr\n",
    "        self.U_f -= np.dot(x.T, np.flip(np.array(self.del_forget_gates).reshape((len(self.del_forget_gates), -1)), axis=0))*lr\n",
    "        self.U_o -= np.dot(x.T, np.flip(np.array(self.del_output_gates).reshape((len(self.del_output_gates), -1)), axis=0))*lr\n",
    "        self.U_g -= np.dot(x.T, np.flip(np.array(self.del_gs).reshape((len(self.del_gs), -1)), axis=0))*lr\n",
    "\n",
    "        if self.output_states[:-1]:\n",
    "            reshaped_output_states = np.array(self.output_states[:-1]).reshape((len(self.output_states[:-1]),-1)).T\n",
    "            self.W_i -= np.dot(reshaped_output_states, np.flip(np.atleast_2d(np.squeeze(self.del_input_gates[1:])), axis=0))*lr\n",
    "            self.W_f -= np.dot(reshaped_output_states, np.flip(np.atleast_2d(np.squeeze(self.del_forget_gates[1:])), axis=0))*lr\n",
    "            self.W_o -= np.dot(reshaped_output_states, np.flip(np.atleast_2d(np.squeeze(self.del_output_gates[1:])), axis=0))*lr\n",
    "            self.W_g -= np.dot(reshaped_output_states, np.flip(np.atleast_2d(np.squeeze(self.del_output_gates[1:])), axis=0))*lr\n",
    "\n",
    "        return timestep_error\n",
    "    \n",
    "    def reset(self):\n",
    "        self.input_gates = list()\n",
    "        self.forget_gates = list()\n",
    "        self.output_gates = list()\n",
    "        self.gs = list()\n",
    "        self.cell_states = list()\n",
    "        self.output_states = list()\n",
    "\n",
    "        self.del_output_states = list()\n",
    "        self.del_cell_states = list()\n",
    "        self.del_gs = list()\n",
    "        self.del_input_gates = list()\n",
    "        self.del_forget_gates = list()\n",
    "        self.del_output_gates = list()\n",
    "\n",
    "        self.cell_state = self.cell_state*0\n",
    "        self.output_state = self.output_state*0\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        output = list()\n",
    "        for row in x:\n",
    "            input_gate = self.sigmoid(np.dot(row, self.U_i) + np.dot(self.output_state, self.W_i))\n",
    "            forget_gate = self.sigmoid(np.dot(row, self.U_f) + np.dot(self.output_state, self.W_f))\n",
    "            output_gate = self.sigmoid(np.dot(row, self.U_o) + np.dot(self.output_state, self.W_o))\n",
    "            g = np.tanh(np.dot(row, self.U_g) + np.dot(self.output_state, self.W_g))\n",
    "            self.cell_state = self.cell_state*forget_gate + g*input_gate\n",
    "            self.output_state = np.tanh(self.cell_state)*output_gate\n",
    "            output.append(self.output_state)\n",
    "        self.reset()\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train(model,x, seq_length, epochs, lr):\n",
    "    length = len(x)\n",
    "    train_loss = []\n",
    "    no_epoch = []\n",
    "    trainloss = []\n",
    "    for epoch in range(epochs):\n",
    "        no_epoch += [epoch]\n",
    "        print ('iteration {0}'.format(epoch))\n",
    "        for b in range(0, length, seq_length):\n",
    "            if b == seq_length:\n",
    "                break;\n",
    "            for c in range(b, seq_length):\n",
    "                model.forward(lstm,x[c])\n",
    "            trainloss += model.backward(lstm, x[c-seq_length+1:c+1], x[c-seq_length+2:c+2], seq_length, lr)\n",
    "            trainloss/=length\n",
    "            model.reset()\n",
    "        train_loss += [trainloss]\n",
    "    toplot = [train_loss]\n",
    "    labels = ['Training loss']\n",
    "    graph(toplot, labels, 'Training Loss vs epochs', 'epochs', 'Training Loss', no_epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate(model, start, length, temperature, sequence_len):  \n",
    "    text = []\n",
    "    text.append(start)\n",
    "\n",
    "    for i in range(length-1):\n",
    "        begin = max(0, len(text)-sequence_len)\n",
    "        end = len(text)\n",
    "        next_char = model.predict(text[begin:end], temperature)\n",
    "        text.append(next_char)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def graph(toplot, labels, title, xlabel, ylabel, no_epoch):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    for i in range(len(toplot)):\n",
    "        plt.plot(no_epoch, toplot[i], label = labels[i])\n",
    "        \n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def read_file(filename):\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        x = f.read()\n",
    "    x_train = [ord(letter) for letter in x]\n",
    "    unique = len(set(x))\n",
    "    print ('There are %d unique characters\\n' %unique)\n",
    "    return np.array(x_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = 'novel.txt'\n",
    "hidden_size = 100\n",
    "learning_rate = 0.01\n",
    "num_epochs = 24\n",
    "sequence_len = 5\n",
    "print_freq = 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lstm = LSTM(2, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = read_file(filename)\n",
    "\n",
    "print 'Training with'\n",
    "print ('hidden_size = %d, learning_rate = %f, sequence_len = %d, num_epochs = %d\\n' \\\n",
    "%(hidden_size, learning_rate, sequence_len, num_epochs))\n",
    "\n",
    "\n",
    "train(LSTM, x, sequence_len, num_epochs, learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "Expected results are that lstm would learn and generalize better than vanilla rnn as it can capture long term dependancies well.\n",
    "\n",
    "The code had a few bugs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
